# kubectl-ai Configuration for Todo App

# Configuration for AI-assisted Kubernetes operations
[kubectl-ai]
model = "gpt-4-turbo"  # Use appropriate model for cluster management
temperature = 0.1       # Low temperature for consistent, reliable commands
max_tokens = 2048       # Sufficient for complex kubectl commands

# Context-specific configurations for the todo app
[todo-app-context]
namespace = "todo-app-prod"
resources = ["deployments", "services", "ingresses", "pods", "configmaps", "secrets"]
monitoring_resources = ["horizontalpodautoscalers", "networkpolicies"]

# AI command aliases for common todo app operations
[aliases]
scale-frontend = "kubectl scale deployment todo-app-frontend --replicas={{count}} -n todo-app-prod"
scale-backend = "kubectl scale deployment todo-app-backend --replicas={{count}} -n todo-app-prod"
check-health = "kubectl get pods,services,ingresses -n todo-app-prod"
restart-frontend = "kubectl rollout restart deployment todo-app-frontend -n todo-app-prod"
restart-backend = "kubectl rollout restart deployment todo-app-backend -n todo-app-prod"
view-logs-frontend = "kubectl logs -l app=frontend -n todo-app-prod --tail=100"
view-logs-backend = "kubectl logs -l app=backend -n todo-app-prod --tail=100"

# Security policies for AI-assisted operations
[security]
allowed_namespaces = ["todo-app-prod", "monitoring", "ingress-nginx"]
blocked_operations = ["delete namespaces", "patch rbac", "modify secrets"]
require_approval = ["scale-up", "restart", "delete"]

# Performance monitoring for AI recommendations
[performance]
cpu_threshold = 80      # Percentage of CPU limit that triggers scaling recommendation
memory_threshold = 85   # Percentage of memory limit that triggers scaling recommendation
response_time_threshold = 2.0  # Seconds that trigger performance recommendations